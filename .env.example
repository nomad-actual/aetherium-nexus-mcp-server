MCP_SERVER_PORT=3000
MCP_SERVER_HOST=localhost
MCP_SERVER_CORS_ALLOWED_ORIGINS=127.0.0.1|localhost
MCP_SERVER_CORS_ALLOWED_HOSTS=127.0.0.1|localhost
MCP_SERVER_TITLE=Simply Lovely MCP Server

# default is Los Angeles
DEFAULT_LOCATION_LAT=34.052235
DEFAULT_LOCATION_LON=-118.243683

TIMESERVER_HOST=time.nist.gov                    # can be nist.gov or ntp.ubuntu.com, etc or your own
TIMESERVER_PORT=123                              # default is 123
TIMESERVER_TIMEOUT=200                           # default is 200ms

LOCALE_REGION=en-US
LOCALE_UNITS=imperial                            # imperial or metric or auto (auto infers from region)
LOCALE_MONTH_STYLE=short                         # short, long, numeric (Jul, July, 7)
LOCALE_SHOWWEEKDAY=true
LOCALE_USE_24HR=false

SEARCH_HOST=                                     # pimary use searxng
SEARCH_TIMEOUT=10000                             # milliseconds
SEARCH_PAGE_CONTENT_LIMIT=5000                   # Cuts off the sentence just after this length
SEARCH_MAX_RESULTS=10

LOCALE_REGION=en-US
LOCALE_UNITS=imperial                            # imperial or metric or auto (auto infers from region)
LOCALE_MONTH_STYLE=short                         # short, long, narrow (Jul, July, 7)
LOCALE_SHOWWEEKDAY=true
LOCALE_USE_24HR=false



# RAG CONFIGURATION (json | opensearch supported)
RAG_DATASTORE=json

RAG_STORAGE_URI=file:///home/your user here/some dir/embeddings.json
# RAG_STORAGE_URI=http://opensearchurl:9200
RAG_LIMIT_RESULTS=5
RAG_SOURCE_DIRECTORIES=/home/info|/opt/something
RAG_INCLUDE_FILE_EXT=.pdf|.md                    # probably shouldn't touch yet
RAG_MAX_FILE_SIZE_MB=10
RAG_IGNORE_DIRS=dir1*|dir2|.dir3


# LLM CLIENT OPTIONS (used for RAG embeddings)
LLM_HOST=http://localhost:11434

# have tried these but qwen3-embedding works the best. 
# todo: opensearch dimension tuning is not tunable yet

# 'snowflake-arctic-embed2:568m'
# hf.co/Qwen/Qwen3-Embedding-0.6B-GGUF:Q8_0
EMBEDDING_MODEL=hf.co/Qwen/Qwen3-Embedding-4B-GGUF:Q5_K_M
EMBEDDING_MODEL_CONTEXT=8192

# note must have SEMANTIC_SEARCH_MODEL set
SEMANTIC_SEARCH_ENABLED=false

# this can be anything but proven to work well with qwen3:4b
SEMANTIC_SEARCH_MODEL=hf.co/bartowski/Qwen_Qwen3-4B-Instruct-2507-GGUF:Q4_K_M
SEMANTIC_SEARCH_MODEL_CONTEXT=8192

